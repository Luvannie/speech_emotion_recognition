{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":653195,"sourceType":"datasetVersion","datasetId":325566},{"sourceId":256618,"sourceType":"datasetVersion","datasetId":107620},{"sourceId":639622,"sourceType":"datasetVersion","datasetId":316368}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-22T07:29:46.264667Z","iopub.execute_input":"2023-12-22T07:29:46.265521Z","iopub.status.idle":"2023-12-22T07:29:46.271049Z","shell.execute_reply.started":"2023-12-22T07:29:46.265477Z","shell.execute_reply":"2023-12-22T07:29:46.270142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport sys\n\n# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\nimport librosa\nimport librosa.display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\nfrom IPython.display import Audio","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:25.256362Z","iopub.execute_input":"2023-12-22T07:32:25.256841Z","iopub.status.idle":"2023-12-22T07:32:25.262764Z","shell.execute_reply.started":"2023-12-22T07:32:25.256806Z","shell.execute_reply":"2023-12-22T07:32:25.261465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\nravdess_directory_list = os.listdir(ravdess)\nprint(ravdess_directory_list)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:06.732086Z","iopub.execute_input":"2023-12-22T07:31:06.732996Z","iopub.status.idle":"2023-12-22T07:31:06.753889Z","shell.execute_reply.started":"2023-12-22T07:31:06.732959Z","shell.execute_reply":"2023-12-22T07:31:06.753043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Crema = \"/kaggle/input/cremad/AudioWAV/\"\nTess = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:06.755817Z","iopub.execute_input":"2023-12-22T07:31:06.756141Z","iopub.status.idle":"2023-12-22T07:31:06.760622Z","shell.execute_reply.started":"2023-12-22T07:31:06.756110Z","shell.execute_reply":"2023-12-22T07:31:06.759754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## RAVDESS\nFilename identifiers\n\nModality (01 = full-AV, 02 = video-only, 03 = audio-only).\n\nVocal channel (01 = speech, 02 = song).\n\nEmotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n\nEmotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n\nStatement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n\nRepetition (01 = 1st repetition, 02 = 2nd repetition).\n\nActor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n\nFilename example: 03-01-06-01-02-01-12.wav\n\nAudio-only (03) Speech (01) Fearful (06) Normal intensity (01) Statement \"dogs\" (02) 1st Repetition (01) 12th Actor (12) Female, as the actor ID number is even.","metadata":{}},{"cell_type":"code","source":"file_emotion = []\nfile_path = []\nfor i in ravdess_directory_list:\n    # vì có 24 diễn viên khác nhau nên cần trích xuất file cho mỗi actor\n    actor = os.listdir(ravdess + i)\n    for f in actor:\n        part = f.split('.')[0].split('-')\n    # third part in each file represents the emotion associated to that file.\n    # phần thứ 3 trong mỗi file đại diện cho cảm xúc chính của file\n        file_emotion.append(int(part[2]))\n        file_path.append(ravdess + i + '/' + f)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:06.761739Z","iopub.execute_input":"2023-12-22T07:31:06.761997Z","iopub.status.idle":"2023-12-22T07:31:07.508128Z","shell.execute_reply.started":"2023-12-22T07:31:06.761974Z","shell.execute_reply":"2023-12-22T07:31:07.507344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tạo dataframe cho emotion\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n#dataframe cho đường dẫn của file\npath_df = pd.DataFrame(file_path, columns=['Path'])\nravdess_df = pd.concat([emotion_df, path_df], axis=1)\n#chuyển đổi số thành cảm xúc thật \n# vì các dataset khác không có calm, là cái số 2, nên chuyển calm thành neutral\nravdess_df.Emotions.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust',\n                             8:'surprise'},\n                            inplace=True)\nprint(ravdess_df.head())\nprint(\"______________________________________________\")\nprint(ravdess_df.tail())\nprint(\"_______________________________________________\")\nprint(ravdess_df.Emotions.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:07.509178Z","iopub.execute_input":"2023-12-22T07:31:07.509481Z","iopub.status.idle":"2023-12-22T07:31:07.575511Z","shell.execute_reply.started":"2023-12-22T07:31:07.509454Z","shell.execute_reply":"2023-12-22T07:31:07.574545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CREMA-D\nCREMA-D is a data set of 7,442 original clips from 91 actors. These clips were from 48 male and 43 female actors between the ages of 20 and 74 coming from a variety of races and ethnicities (African America, Asian, Caucasian, Hispanic, and Unspecified). Actors spoke from a selection of 12 sentences. The sentences were presented using one of six different emotions (Anger, Disgust, Fear, Happy, Neutral, and Sad) and four different emotion levels (Low, Medium, High, and Unspecified).","metadata":{}},{"cell_type":"code","source":"crema_directory_list = os.listdir(Crema)\n\nfile_emotion = []\nfile_path = []\n\nfor file in crema_directory_list:\n    # storing file paths\n    file_path.append(Crema + file)\n    # storing file emotions\n    part=file.split('_')\n    if part[2] == 'SAD':\n        file_emotion.append('sad')\n    elif part[2] == 'ANG':\n        file_emotion.append('angry')\n    elif part[2] == 'DIS':\n        file_emotion.append('disgust')\n    elif part[2] == 'FEA':\n        file_emotion.append('fear')\n    elif part[2] == 'HAP':\n        file_emotion.append('happy')\n    elif part[2] == 'NEU':\n        file_emotion.append('neutral')\n    else:\n        file_emotion.append('Unknown')\n        \n# tạo dataframe cho emotion\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n\n# tạo dataframe cho đường dẫn\npath_df = pd.DataFrame(file_path, columns=['Path'])\nCrema_df = pd.concat([emotion_df, path_df], axis=1)\nCrema_df.head()\nprint(Crema_df.Emotions.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:07.578729Z","iopub.execute_input":"2023-12-22T07:31:07.578986Z","iopub.status.idle":"2023-12-22T07:31:08.306930Z","shell.execute_reply.started":"2023-12-22T07:31:07.578964Z","shell.execute_reply":"2023-12-22T07:31:08.305808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TESS\nThere are a set of 200 target words were spoken in the carrier phrase \"Say the word _' by two actresses (aged 26 and 64 years) and recordings were made of the set portraying each of seven emotions (anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral). There are 2800 data points (audio files) in total.\n\nThe dataset is organised such that each of the two female actor and their emotions are contain within its own folder. And within that, all 200 target words audio file can be found. The format of the audio file is a WAV format","metadata":{}},{"cell_type":"code","source":"tess_directory_list = os.listdir(Tess)\nfile_emotion = []\nfile_path = []\n\nfor dir in tess_directory_list:\n    directories = os.listdir(Tess + dir)\n    for file in directories:\n        part = file.split('.')[0]\n        part = part.split('_')[2]\n        if part=='ps':\n            file_emotion.append('surprise')\n        else:\n            file_emotion.append(part)\n        file_path.append(Tess + dir + '/' + file)\n        \n# dataframe cho emotion\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n# dataframe cho đường dẫn của file\npath_df = pd.DataFrame(file_path, columns=['Path'])\nTess_df = pd.concat([emotion_df, path_df], axis=1)\nTess_df.head()\nprint(Tess_df.Emotions.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:08.308223Z","iopub.execute_input":"2023-12-22T07:31:08.309266Z","iopub.status.idle":"2023-12-22T07:31:08.965434Z","shell.execute_reply.started":"2023-12-22T07:31:08.309227Z","shell.execute_reply":"2023-12-22T07:31:08.964540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Join dataset","metadata":{}},{"cell_type":"code","source":"# creating Dataframe using all the 4 dataframes we created so far.\ndata_path = pd.concat([ravdess_df, Crema_df, Tess_df], axis = 0)\ndata_path.to_csv(\"data_path.csv\",index=False)\ndata_path.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:08.966779Z","iopub.execute_input":"2023-12-22T07:31:08.967431Z","iopub.status.idle":"2023-12-22T07:31:09.045544Z","shell.execute_reply.started":"2023-12-22T07:31:08.967395Z","shell.execute_reply":"2023-12-22T07:31:09.044724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_path.Emotions.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:09.046478Z","iopub.execute_input":"2023-12-22T07:31:09.046723Z","iopub.status.idle":"2023-12-22T07:31:09.053862Z","shell.execute_reply.started":"2023-12-22T07:31:09.046702Z","shell.execute_reply":"2023-12-22T07:31:09.052985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đếm số lần mỗi cảm xúc xuất hiện\nemotion_counts = data_path['Emotions'].value_counts()\n\n# Vẽ biểu đồ cột\nplt.figure(figsize=(10, 6))\nplt.title('Count of Emotions', size=16)\nsns.barplot(x=emotion_counts.index, y=emotion_counts.values)\nplt.ylabel('Count', size=12)\nplt.xlabel('Emotions', size=12)\nplt.xticks(rotation=45)  # Xoay nhãn trục x nếu cần thiết\nsns.despine(top=True, right=True, left=False, bottom=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:09.054983Z","iopub.execute_input":"2023-12-22T07:31:09.055288Z","iopub.status.idle":"2023-12-22T07:31:09.464186Z","shell.execute_reply.started":"2023-12-22T07:31:09.055258Z","shell.execute_reply":"2023-12-22T07:31:09.463324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_array, sample_rate = librosa.load(data_path['Path'].iloc[0])\nsample_rate","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:31:09.465531Z","iopub.execute_input":"2023-12-22T07:31:09.465875Z","iopub.status.idle":"2023-12-22T07:31:18.957746Z","shell.execute_reply.started":"2023-12-22T07:31:09.465843Z","shell.execute_reply":"2023-12-22T07:31:18.956692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipd.Audio(data_array,rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:33.562440Z","iopub.execute_input":"2023-12-22T07:32:33.563404Z","iopub.status.idle":"2023-12-22T07:32:33.593851Z","shell.execute_reply.started":"2023-12-22T07:32:33.563365Z","shell.execute_reply":"2023-12-22T07:32:33.592971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE LOG MEL SPECTROGRAM\nplt.figure(figsize=(10, 5))\n#melspectrogram là biểu đồ biểu diễn âm thanh dưới dạng các vách ngắn đo trong một không gian mel\nspectrogram = librosa.feature.melspectrogram(y=data_array, sr=sample_rate, n_mels=128,fmax=5000) \n#chuyển đổi melspectrogram sang đơn vị Decibel\nlog_spectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(log_spectrogram, y_axis='mel', sr=sample_rate, x_axis='time');\nplt.title('Mel Spectrogram ')\nplt.colorbar(format='%+2.0f dB')","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:38.830027Z","iopub.execute_input":"2023-12-22T07:32:38.830388Z","iopub.status.idle":"2023-12-22T07:32:40.604611Z","shell.execute_reply.started":"2023-12-22T07:32:38.830361Z","shell.execute_reply":"2023-12-22T07:32:40.603672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tính toán các đặc trưng mfcc (mel-frequency cpestral coeffcients)\nmfcc = librosa.feature.mfcc(y=data_array, sr=sample_rate, n_mfcc=30)\n'''\nKết quả trả về là một ma trận có kích thước (n_mfcc, T), trong đó n_mfcc\nlà số lượng hệ số MFCC và T là số khung thời gian trong tín hiệu âm thanh.\nMỗi hàng của ma trận tương ứng với một hệ số MFCC và mỗi cột tương ứng với\nmột khung thời gian. MFCC thường được sử dụng để biểu diễn đặc trưng âm thanh\nvà thường được sử dụng trong các ứng dụng xử lý tiếng nói và âm nhạc.\n'''\n# MFCC\nplt.figure(figsize=(16, 10))\nplt.subplot(3,1,1)\nlibrosa.display.specshow(mfcc, x_axis='time')\nplt.ylabel('MFCC')\nplt.colorbar()\n\nipd.Audio(data_array,rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:40.606201Z","iopub.execute_input":"2023-12-22T07:32:40.606464Z","iopub.status.idle":"2023-12-22T07:32:40.998622Z","shell.execute_reply.started":"2023-12-22T07:32:40.606441Z","shell.execute_reply":"2023-12-22T07:32:40.997634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"# NOISE- nhiễu\ndef noise(data):\n    noise_amp = 0.045*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\n# STRETCH-giãn\ndef stretch(data, rate=0.8):\n    return librosa.effects.time_stretch(data,rate=rate)\n# SHIFT-dịch chuyển\ndef shift(data):\n    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n    return np.roll(data, shift_range)\n# PITCH - biến đổi tần số\ndef pitch(data, sampling_rate, pitch_factor=0.7):\n    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:41.000159Z","iopub.execute_input":"2023-12-22T07:32:41.000575Z","iopub.status.idle":"2023-12-22T07:32:41.008267Z","shell.execute_reply.started":"2023-12-22T07:32:41.000538Z","shell.execute_reply":"2023-12-22T07:32:41.007288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# audio ban đầu\nplt.figure(figsize=(12, 5))\nlibrosa.display.waveshow(y=data_array, sr=sample_rate)\nipd.Audio(data_array,rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:41.010527Z","iopub.execute_input":"2023-12-22T07:32:41.010849Z","iopub.status.idle":"2023-12-22T07:32:41.550270Z","shell.execute_reply.started":"2023-12-22T07:32:41.010820Z","shell.execute_reply":"2023-12-22T07:32:41.549375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AUDIO thêm nhiễu\nx = noise(data_array)\nplt.figure(figsize=(12,5))\nlibrosa.display.waveshow(y=x, sr=sample_rate)\nipd.Audio(x, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:41.551559Z","iopub.execute_input":"2023-12-22T07:32:41.551907Z","iopub.status.idle":"2023-12-22T07:32:42.172850Z","shell.execute_reply.started":"2023-12-22T07:32:41.551875Z","shell.execute_reply":"2023-12-22T07:32:42.171951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# audio giãn\nx = stretch(data_array)\nplt.figure(figsize=(12, 5))\nlibrosa.display.waveshow(y=x, sr=sample_rate)\nipd.Audio(x, rate=sample_rate)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:42.174205Z","iopub.execute_input":"2023-12-22T07:32:42.174546Z","iopub.status.idle":"2023-12-22T07:32:44.048219Z","shell.execute_reply.started":"2023-12-22T07:32:42.174492Z","shell.execute_reply":"2023-12-22T07:32:44.046997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# audio bị dịch\nx = shift(data_array)\nplt.figure(figsize=(12, 5))\nlibrosa.display.waveshow(y=x, sr=sample_rate)\nipd.Audio(x, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:44.049493Z","iopub.execute_input":"2023-12-22T07:32:44.049805Z","iopub.status.idle":"2023-12-22T07:32:44.529235Z","shell.execute_reply.started":"2023-12-22T07:32:44.049777Z","shell.execute_reply":"2023-12-22T07:32:44.528233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# audio\nx = pitch(data=data_array,sampling_rate=sample_rate)\nplt.figure(figsize=(12, 5))\nlibrosa.display.waveshow(y=x, sr=sample_rate)\nipd.Audio(x, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:44.530520Z","iopub.execute_input":"2023-12-22T07:32:44.530809Z","iopub.status.idle":"2023-12-22T07:32:45.084588Z","shell.execute_reply.started":"2023-12-22T07:32:44.530784Z","shell.execute_reply":"2023-12-22T07:32:45.083665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"# tính tỉ lệ vượt ngưỡng của dữ liệu âm thanh- trả về mảng 1 chiều\ndef zcr(data,frame_length,hop_length):\n    zcr=librosa.feature.zero_crossing_rate(y=data,frame_length=frame_length,hop_length=hop_length)\n    return np.squeeze(zcr)\n# hàm tính root mean square error\ndef rmse(data,frame_length=2048,hop_length=512):\n    rmse=librosa.feature.rms(y=data,frame_length=frame_length,hop_length=hop_length)\n    return np.squeeze(rmse)\n#mfcc\ndef mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n'''\ntrích xuất feature Hàm này kết hợp các đặc trưng ZCR, RMSE, và MFCC\nđể tạo một vectơ đặc trưng hoàn chỉnh cho dữ liệu âm thanh.\n'''\ndef extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n    result=np.array([])\n    \n    result=np.hstack((result,\n                      zcr(data,frame_length,hop_length),\n                      rmse(data,frame_length,hop_length),\n                      mfcc(data,sr,frame_length,hop_length)\n                     ))\n    return result\n\ndef get_features(path,duration=2.5, offset=0.6):\n    data,sr=librosa.load(path = path,duration=duration,offset=offset)\n    aud=extract_features(data) # trích xuất feature\n    audio=np.array(aud) # chuyển các feature thành array\n    \n    noised_audio=noise(data)\n    aud2=extract_features(noised_audio)\n    audio=np.vstack((audio,aud2))\n    \n    pitched_audio=pitch(data,sr)\n    aud3=extract_features(pitched_audio)\n    audio=np.vstack((audio,aud3))\n    \n    pitched_audio1=pitch(data,sr)\n    pitched_noised_audio=noise(pitched_audio1)\n    aud4=extract_features(pitched_noised_audio)\n    audio=np.vstack((audio,aud4))\n    \n    return audio","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:45.085899Z","iopub.execute_input":"2023-12-22T07:32:45.086257Z","iopub.status.idle":"2023-12-22T07:32:45.098581Z","shell.execute_reply.started":"2023-12-22T07:32:45.086224Z","shell.execute_reply":"2023-12-22T07:32:45.097620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Feature","metadata":{}},{"cell_type":"code","source":"import multiprocessing as mp\nprint(\"Number of processors: \", mp.cpu_count())\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:59.143717Z","iopub.execute_input":"2023-12-22T07:32:59.144587Z","iopub.status.idle":"2023-12-22T07:32:59.149372Z","shell.execute_reply.started":"2023-12-22T07:32:59.144552Z","shell.execute_reply":"2023-12-22T07:32:59.148208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from joblib import Parallel, delayed  # hỗ trợ tính toán sóng song\nimport timeit\nstart = timeit.default_timer()\n# get feature cho từng file uadio\ndef process_feature(path, emotion):\n    features = get_features(path)\n    X = []\n    Y = []\n    for ele in features:\n        X.append(ele)\n        Y.append(emotion)\n    return X, Y\n\npaths = data_path.Path\nemotions = data_path.Emotions\n\n# chạy vòng lặp song song \nresults = Parallel(n_jobs=-1)(delayed(process_feature)(path, emotion) for (path, emotion) in zip(paths, emotions))\n\n# điền kết quả \nX = []\nY = []\nfor result in results:\n    x, y = result\n    X.extend(x)\n    Y.extend(y)\n\n\nstop = timeit.default_timer()\n\nprint('Time: ', stop - start)  ","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:32:59.151185Z","iopub.execute_input":"2023-12-22T07:32:59.151449Z","iopub.status.idle":"2023-12-22T07:43:22.225559Z","shell.execute_reply.started":"2023-12-22T07:32:59.151425Z","shell.execute_reply":"2023-12-22T07:43:22.224358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X), len(Y), data_path.Path.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:43:22.227603Z","iopub.execute_input":"2023-12-22T07:43:22.228542Z","iopub.status.idle":"2023-12-22T07:43:22.235233Z","shell.execute_reply.started":"2023-12-22T07:43:22.228483Z","shell.execute_reply":"2023-12-22T07:43:22.234313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Feature","metadata":{}},{"cell_type":"code","source":"emotions = pd.DataFrame(X)\nemotions['Emotions'] = Y\nemotions.to_csv('emotion.csv', index=False)\nemotions.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T07:43:22.236418Z","iopub.execute_input":"2023-12-22T07:43:22.237081Z","iopub.status.idle":"2023-12-22T07:46:57.892800Z","shell.execute_reply.started":"2023-12-22T07:43:22.237032Z","shell.execute_reply":"2023-12-22T07:46:57.891810Z"},"trusted":true},"execution_count":null,"outputs":[]}]}